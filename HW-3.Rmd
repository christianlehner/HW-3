---
title: "MATH 216 Homework 3"
author: "Christian Lehner"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(Quandl))
suppressPackageStartupMessages(library(reshape2))
suppressPackageStartupMessages(library(car))
suppressPackageStartupMessages(library(stats))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(knitr))
```


## Admistrative:

Please indicate

* Who you collaborated with: Delaney Paul Kyler
* Roughly how much time you spent on this HW:15
* What gave you the most trouble:lubridate
* Any comments you have: working on the bitcoin and gold one still


## Data

* You must first copy the file `profiles.csv` from `HW-2` to the `data` folder
in the `HW-3` directory
* We also consider all 222,540 songs played in the Reed College pool hall
jukebox from Nov 30, 2003 to Jan 22, 2009 (included in `HW-3` folder). 


```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
profiles <- read.csv("/Users/christianlehner/Desktop/Spring 2016/Data Science/HW 3/copyofprofiles.csv", header=TRUE) %>% 
  tbl_df()
jukebox <- read.csv("/Users/christianlehner/Desktop/Spring 2016/Data Science/HW 3/data/jukebox.csv", header=TRUE) %>% 
  tbl_df()
```

```{r, echo=FALSE, cache=TRUE}
essays <- select(profiles, contains("essay")) #splitting data
profiles <- select(profiles, -contains("essay"))
profiles <- profiles %>% 
  mutate(is.female = ifelse(sex == "f", 1, 0)) #adding binary numeric variable for gender
jukebox[jukebox==""] <- NA
profiles[profiles==""] <- NA
essays[essays==""] <- NA
profiles$last_online <- as.Date(profiles$last_online)
```

## Question 1:
For this question we will be picking up from where we left off in HW-2,
specifically the OkCupid dataset.
### a)

Using your exploratory data analysis from HW-2, fit a logistic regression to predict individual's gender and interpret the results for one continuous variable (if you used one) and one categorical variable of your choice
gender ~ height + bodytype(binned binary)

When fitting the logistic regression, you can put both the categorical variable and the numerical variable you've chosen in the same model, that way you have more information to predict gender, and only have a single set of predictions to evaluate.
Don't worry about cross-validation for this assignment (i.e. out of sample prediction), only focus on predicting the dataset itself (within sample prediction).
Part d) is now a bonus question.

```{r, echo=FALSE, fig.width=12, fig.height=6}
ggplot_missing <- function(x){
  x %>% 
    is.na %>%
    melt %>%
    ggplot(data = .,
           aes(x = Var2,
               y = Var1)) +
    geom_raster(aes(fill = value)) +
    scale_fill_grey(name = "",
                    labels = c("Present","Missing")) +
    theme_minimal() + 
    theme(axis.text.x  = element_text(angle=90, vjust=.5)) + 
    labs(x = "Variables in Dataset",
         y = "Rows / observations", title="Missing Values of Random Sample")
} #not my code thanks to Nicholas Tierney, at http://www.njtierney.com/r/missing%20data/rbloggers/2015/12/01/ggplot-missing-data/
ggplot_missing(profiles) #shows which variables have the most missing

```
I looked at the variables that had the most amount of missing values to see what 
variables people either on purpose left blank or where to lazy to answer. 
If there are also patterns in the missing values, say they only added certain 
questions later this would be important.

```{r, echo=FALSE, fig.width=12, fig.height=6}
profiles_body <- profiles %>% 
  group_by(sex,body_type) %>% 
  tally() %>% 
  mutate(prop=n/sum(n))

profiles_body$body_type<-recode(profiles_body$body_type,"'athletic'='masculine'") 
profiles_body$body_type<-recode(profiles_body$body_type,"'jacked'='masculine'") 
profiles_body$body_type<-recode(profiles_body$body_type,"'fit'='masculine'") 
profiles_body$body_type<-recode(profiles_body$body_type,"'average'='masculine'")
profiles_body$body_type<-recode(profiles_body$body_type,"'used up'='masculine'") 
profiles_body$body_type<-recode(profiles_body$body_type,"'overweight'='masculine'")
profiles_body$body_type<-recode(profiles_body$body_type,"'a little extra'='masculine'") 
profiles_body$body_type<-recode(profiles_body$body_type,"'a little extra'='femine'")
profiles_body$body_type<-recode(profiles_body$body_type,"'thin'='femine'")
profiles_body$body_type<-recode(profiles_body$body_type,"'full figured'='femine'")
profiles_body$body_type<-recode(profiles_body$body_type,"'curvy'='femine'")
profiles_body$body_type<-recode(profiles_body$body_type,"'rather not say'='femine'")
profiles_body$body_type<-recode(profiles_body$body_type,"'NA'='femine'")
profiles_body$body_type<-recode(profiles_body$body_type,"'skinny'='femine'")
profiles_body$body_type<-recode(profiles_body$body_type,"NA='femine'")


body_type<- ggplot(profiles_body, aes(body_type, prop, fill=sex))+
  geom_bar(stat="identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
body_type

```

I binned all the factors of the body type variable into two factors, creating a dichotomous variable for the logistic regression.
I first plotted the variables to determine which factors should be added to masculine or feminine. 
I also looked at the two distributions of heights. Notice the "jump" at around 72 inches, 6 ft, in the male height distribution; I believe that is jump is less due to 
physiological reasons as much as psychological ones.

```{r, echo=FALSE, fig.width=12, fig.height=6}
heights <- ggplot(data=profiles, aes(x=height)) + 
  geom_histogram(aes(y=..density..), binwidth = 1) + 
  facet_wrap(~sex, nrow=2) +
  coord_cartesian(xlim=c(55,85)) +
  geom_vline(aes(xintercept = as.numeric(72), linetype = "4"), show.legend = FALSE, data = profiles)
heights

p <- ggplot(data=profiles,aes(x=sex, y=height)) +
  geom_violin(scale="area") +
  scale_y_continuous(limits = c(57, 78))
p



profiles_1 <- profiles %>% 
  select(is.female, height, body_type)

profiles_1$body_type<-recode(profiles_1$body_type,"'athletic'='masculine'") 
profiles_1$body_type<-recode(profiles_1$body_type,"'jacked'='masculine'") 
profiles_1$body_type<-recode(profiles_1$body_type,"'fit'='masculine'") 
profiles_1$body_type<-recode(profiles_1$body_type,"'average'='masculine'")
profiles_1$body_type<-recode(profiles_1$body_type,"'used up'='masculine'") 
profiles_1$body_type<-recode(profiles_1$body_type,"'overweight'='masculine'")
profiles_1$body_type<-recode(profiles_1$body_type,"'a little extra'='masculine'") 
profiles_1$body_type<-recode(profiles_1$body_type,"'a little extra'='femine'")
profiles_1$body_type<-recode(profiles_1$body_type,"'thin'='femine'")
profiles_1$body_type<-recode(profiles_1$body_type,"'full figured'='femine'")
profiles_1$body_type<-recode(profiles_1$body_type,"'curvy'='femine'")
profiles_1$body_type<-recode(profiles_1$body_type,"'rather not say'='femine'")
profiles_1$body_type<-recode(profiles_1$body_type,"'NA'='femine'")
profiles_1$body_type<-recode(profiles_1$body_type,"'skinny'='femine'")
profiles_1$body_type<-recode(profiles_1$body_type,"NA='femine'")

ggplot(data=profiles_1, aes(x=is.female, y=height)) +
  geom_jitter(height = .2, alpha = .3, aes(colour = body_type), size = 3)

#ggplot(aes(x=reorder(eth1, n), y = n))

profiles_1 <- na.omit(profiles_1)
which(! complete.cases(profiles_1))
log_reg <- glm(is.female ~.,family=binomial(link='logit'),data=profiles_1) #logistic regression using heights and body type
summary(log_reg) #summary




```
43.639564-0.636127(height)-1.314507(body_type)

### b)

Plot a histogram of the fitted probabilities $\widehat{p}_i$ for all users $i=1,
\ldots, n=59943$ in your dataset.

```{r, echo=FALSE, fig.width=12, fig.height=6}
threshold <- .5
profiles_prob <- profiles_1 %>% 
  mutate(p.hat=fitted(log_reg))

profiles_prob <- as.data.frame(profiles_prob)
profiles_prob$predicted.female <- profiles_prob$p.hat >= threshold

mosaicplot(~ is.female + predicted.female, data = profiles_prob, color = TRUE, main = "Mosaic of Contigency")

probs <- ggplot(profiles_prob, aes(p.hat))+
  geom_histogram() 
probs + geom_vline(aes(xintercept = as.numeric(threshold), linetype = "4"), show.legend = FALSE, data = profiles_prob)

prob <- ggplot(profiles_prob, aes((log(p.hat/(1-p.hat))), p.hat))+
  geom_point() + 
  labs(title="Values of p.hat versus logit_p.hat")
prob
profiles_prob$body <- ifelse(profiles_prob$body_type =="masculine", c(1), c(0))
prob <- ggplot(profiles_prob, aes(height,(43.639564 - 0.636127*(height)-1.314507*(body))))+
  geom_bar(stat="identity") + labs(title="Shows Cuttoff of Height Where Predictions Change") +
  geom_vline(aes(xintercept = ((43.639564-1.314507*0.5)/(0.636127)), colour = "red", legend = FALSE))
prob
```
The fitted probabilities are not consistent not all of the probabilities this is due to our explanatory variables.
The mosaic plot shows visually what proportion of sex is predicted correctly or not. I would say that because masculinity is fragile, our type one error 
would be predicting a male to be female and this model does OK at minimizing this. 

### c)

Use a *decision threshold* of $p^*=0.5$ to make an explicit prediction for each
user $i$'s sex and save this in a variable `predicted_sex`. In other words, for user $i$

* If $\widehat{p}_i > p^*$, set `predicted_sex = 1` i.e. they are female
* If $\widehat{p}_i < p^*$, set `predicted_sex = 0` i.e. they are male

Display a 2 x 2 contingency table of `sex` and `predicted_sex` i.e. compare the 
predicted sex to the actual sex of all users. The sum of all the elements in
your table should be $n=59943$. Comment on how well our predictions fared.

```{r, echo=FALSE, fig.width=12, fig.height=6}

g<- profiles_prob %>%
  group_by(is.female,predicted.female) %>% 
  tally()
g

kable(spread(g, predicted.female, n))

```
The predictions did OK. We miss predicted 3958 males to be female but because our sample is roughly 60,000 this is not to bad. 
I wonder what other variables could create a more predictive model. Cross validation could also definitely help.
### d)

Say we wanted to have a **false positive rate** of about 20%, i.e. of the people
we predicted to be female, we want to be wrong no more than 20% of the time. What
decision threshold $p^*$ should we use?

```{r, echo=FALSE, fig.width=12, fig.height=6}

threshold.2 <- 0.2
profiles_prob <- as.data.frame(profiles_prob)
profiles_prob$predicted.female <- profiles_prob$p.hat >= threshold.2
h<- profiles_prob %>%
  group_by(is.female,predicted.female) %>% 
  tally() %>% 
  mutate(prop=(100*(n/59943))) %>% 
  select(-n)
h


kable(spread(h, predicted.female, prop))

```
I dont know the exact mathematical process to this so I just kinda narrowed it down to a threshold of .2,
this brings us only 17.5% of miss predicted males as females. 




## Question 2:

Using the jukebox data, plot a time series of the number of songs played each
week over the entire time period. i.e.

* On the x-axis present actual dates (not something like Week 93, which doesn't 
mean anything to most people).
* On the y-axis present the total number of songs.

What seasonal (i.e. cyclical) patterns do you observe?


```{r, echo=FALSE, fig.width=12, fig.height=6}

jukebox$date  <- parse_date_time(jukebox$date_time, orders="a b d hms y")

#jukebox$date  <- as.Date(as.POSIXct(jukebox$date))
jukebox$date2  <- as.Date(jukebox$date, format = "%d/%b/%Y:%H:%M:%S", 'EST')

jukebox$week <- findInterval(jukebox$date2,
        seq(from =as.Date("2003-11-30"), to=as.Date("2009-01-22"), by="1 week"))

jukebox1 <- jukebox %>% 
  group_by(week) %>% 
  tally() %>% 
  mutate(count_per_w = n)

jukebox1 <- left_join(jukebox, jukebox1, by = "week") %>%
  distinct(week) %>% 
  select(week, count_per_w, date2)

ggplot(jukebox1, aes(date2, count_per_w)) + 
  geom_point(stat="identity", size=.2) +
  geom_line() + 
  labs(title="Count of Songs Played Per Week") +
  geom_vline(xintercept = as.numeric(as.Date(dmy("1/6/2004","1/6/2005","1/6/2006","1/6/2007","1/6/2008","1/6/2009"))), linetype=4, colour="red") +
  geom_vline(xintercept = as.numeric(as.Date(dmy("1/9/2004","1/9/2005","1/9/2006","1/9/2007","1/9/2008","1/9/2009"))), linetype=4, colour="blue")
  
```
It is pretty apparent summer students don't use the juke box as much as those during the normal academic months.




## Question 3:

Using the jukebox data, what are the top 10 artists played during the "graveyard
shift" during the academic year? Define

* the "graveyard shift" as midnight to 8am
* the academic year as September through May (inclusive)

```{r, echo=FALSE, fig.width=12, fig.height=6}
a <- interval(ymd(20030901, tz = "EST"), ymd(20040601, tz = "EST"))
b <- interval(ymd(20040901, tz = "EST"), ymd(20050601, tz = "EST"))
c <- interval(ymd(20050901, tz = "EST"), ymd(20060601, tz = "EST"))
d <- interval(ymd(20060901, tz = "EST"), ymd(20070601, tz = "EST"))
e <- interval(ymd(20070901, tz = "EST"), ymd(20080601, tz = "EST"))
f <- interval(ymd(20080901, tz = "EST"), ymd(20090601, tz = "EST"))

jukebox_academic <- subset(jukebox, date %within% a | date %within% b |date %within% c | date %within% d |date %within% e | date %within% f)

jukebox_grave <- jukebox_academic %>% 
  mutate(hour = hour(jukebox_academic$date)) 
jukebox_songs <- subset(jukebox_grave, hour <= 8, 
                        select=c(track, hour))

jukebox_grave <- subset(jukebox_grave, hour <= 8, 
                        select=c(artist, hour))


jukebox_songs_top <- jukebox_songs %>% 
  group_by(track) %>% 
  tally() 

jukebox_grave_top <- jukebox_grave %>% 
  group_by(artist) %>% 
  tally() 

da <- jukebox_songs_top  %>%
    arrange(-n) %>%
    slice(1:10)
da
df <- jukebox_grave_top %>%
    arrange(-n) %>%
    slice(1:10)
df
kable(da)
kable(df)
```
I sorted by academic year, subsetted it, and then, used the fact that is military time to create a variable with only ours and selected those that 
are less then 8 resulting in only the hours of midnight to 8 am. There is some interesting variety of artists. 



## Question 4:

We want to compare the volatility of 

* bitcoin prices
* gold prices

Let our measure of volatility be the relative change from day-to-day in price. 
Let the reference currency be US dollars. Analyze these results and provide
insight to a foreign currency exchanger.

```{r, echo=FALSE, fig.width=12, fig.height=6}

bitcoin <- Quandl("BAVERAGE/USD") %>% tbl_df()
bitcoin <- rename(bitcoin, Avg = `24h Average`, Total.Volume = `Total Volume`)
bitcoin <- na.omit(bitcoin)
gold <- Quandl("BUNDESBANK/BBK01_WT5511") %>% tbl_df()
gold <- na.omit(gold)

gold <- gold %>% 
  mutate(percentchange_gold= (((Value/lag(Value))-1)*100))
bitcoin <- bitcoin %>% 
  mutate(percentchange_bitcoin= (((Avg/lag(Avg))-1)*100))

volatile <- left_join(bitcoin, gold, by = "Date") %>% 
  mutate(diff_in_vol = (percentchange_bitcoin-percentchange_gold))



bigplot <- ggplot(volatile, aes(Date))
bigplot + geom_line(aes(y = percentchange_bitcoin, colour = "BTC")) +  
  geom_line(aes(y = percentchange_gold, colour = "Gold")) +
  labs(title="Daily Volatily from Previous Price, GOLD, BTC")

smallplot <- ggplot(volatile, aes(Date))
smallplot + 
  geom_line(aes(y = percentchange_bitcoin, colour = "BTC")) +  
  geom_line(aes(y = percentchange_gold, colour = "Gold")) + 
  geom_line(aes(y = diff_in_vol, colour = "Diff Vol")) +
  scale_x_date(limits = as.Date(c('2015-01-01','2015-03-01'))) +
  labs(title="Daily Volatily from Previous Price, GOLD, BTC, in 2015")

diff <- ggplot(data = volatile, aes(Date)) 
diff + geom_line(aes(y = diff_in_vol, colour = "Diff Vol")) + 
  scale_x_date(limits = as.Date(c('2015-01-01','2015-03-01'))) +
  labs(title="Difference in the Daily Percent Change in BTC and GOLD")

```
Bitcoin is more volatile than gold, which is more volatile than most currencies. The volatilities appear to follow each other as they may follow the same trends,
where people desire bitcoins when other currencies are devalued. The market for bitcoin is also open 247365 wherease gold is traded during bankers hours. I suggest 
that people invest carefully in bitcoin, as regulation is sure to follow soon, and the volitility is unprecendented as a currency.
I want to delve farther into this on my second draft.




## Question 5: BONUS:



Using the data loaded from Quandl below, plot a time series using `geom_line()`
comparing cheese and milk production in the US from 1930 to today. Comment on this.

* Cheese [page](https://www.quandl.com/data/USDANASS/NASS_CHEESEPRODUCTIONMEASUREDINLB-Cheese-Production-Measured-In-Lb)
* Milk [page](https://www.quandl.com/data/USDANASS/NASS_MILKPRODUCTIONMEASUREDINLB-Milk-Production-Measured-In-Lb)

```{r, echo=FALSE, fig.width=12, fig.height=6}
cheese <- Quandl("USDANASS/NASS_CHEESEPRODUCTIONMEASUREDINLB") %>% 
  tbl_df()
milk <-  Quandl("USDANASS/NASS_MILKPRODUCTIONMEASUREDINLB") %>% 
  tbl_df()
```

